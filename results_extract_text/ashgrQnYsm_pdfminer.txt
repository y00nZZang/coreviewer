Under review as a conference paper at ICLR 2023

MBRAIN: A MULTI-CHANNEL SELF-SUPERVISED
LEARNING FRAMEWORK FOR BRAIN SIGNALS

Anonymous authors
Paper under double-blind review

ABSTRACT

Brain signals are important quantitative data for understanding physiological ac-
tivities and diseases of human brain. Meanwhile, rapidly developing deep learn-
ing methods offer a wide range of opportunities for better modeling brain signals,
which has attracted considerable research efforts recently. Most existing studies
pay attention to supervised learning methods, which, however, require high-cost
clinical labels. In addition, the huge difference in the clinical patterns of brain
signals measured by invasive (e.g., SEEG) and non-invasive (e.g., EEG) methods
leads to the lack of a unified method. To handle the above issues, in this paper,
we propose to study the self-supervised learning (SSL) framework for brain sig-
nals that can be applied to pre-train either SEEG or EEG data. Intuitively, brain
signals, generated by the firing of neurons, are transmitted among different con-
necting structures in human brain. Inspired by this, we propose to learn implicit
spatial and temporal correlations between different channels (i.e., contacts of the
electrode, corresponding to different brain areas) as the cornerstone for uniformly
modeling different types of brain signals. Specifically, we capture the temporal
correlation by designing the delayed-time-shift prediction task; we represent the
spatial correlation by a graph structure, which is built with proposed multi-channel
CPC whose goal is to maximize the mutual information of each channel and its
correlated ones. We further theoretically prove that our design can lead to a better
predictive representation and propose the instantaneou-time-shift prediction task
based on it. Finally, replace-discriminative-learning task is designed to preserve
the characteristics of each channel. Extensive experiments of seizure detection
on both EEG and SEEG large-scale real-world datasets demonstrate our model
outperforms several state-of-the-art time series SSL and unsupervised models.

1

INTRODUCTION

Brain signals are foundational quantitative data for the study of human brain in the field of neuro-
science. The patterns of brain signals can greatly help us to understand the normal physiological
function of the brain and the mechanism of related diseases. There are many applications of brain
signals, such as cognitive research (Ismail & Karwowski, 2020; Kuanar et al., 2018), emotion recog-
nition (Song et al., 2020; Chen et al., 2019), neurological disorders (Alturki et al., 2020; Yuan et al.,
2019) and so on. Brain signals can be measured by noninvasive or invasive methods (Paluszek
et al., 2015). The noninvasive methods, like electroencephalography (EEG), cannot simultaneously
consider temporal and spatial resolution along with the deep brain information, but they are eas-
ier to implement without any surgery. As for invasive methods like stereoelectroencephalography
(SEEG), they require extra surgeries to insert the recording devices, but have access to more precise
and higher signal-to-noise data. For both EEG and SEEG data, there are multiple electrodes with
contacts (also called channels) that are sampled at a fixed frequency to record brain signals.

Recently, discoveries in the field of neuroscience have inspired advances of deep learning tech-
niques, which in turn promotes neuroscience research. According to the literature, most deep
learning-based studies of brain signals focus on supervised learning (Shoeibi et al., 2021; Rasheed
et al., 2020; Zhang et al., 2021; Craik et al., 2019), which relies on a large number of clinical labels.
However, obtaining accurate and reliable clinical labels requires a high cost. In the meantime, the
emergence of self-supervised learning (SSL) and its great success (Chen & He, 2021; Grill et al.,
2020; He et al., 2020; Brown et al., 2020; Devlin et al., 2018; Raffel et al., 2020; Van den Oord

1

Under review as a conference paper at ICLR 2023

et al., 2018) makes it a predominant learning paradigm in the absence of labels. Therefore, some
recent studies have introduced the means of SSL to extract the representations of brain signal data.
For example, Banville et al. (2021) directly applies general SSL tasks to pre-train EEG data, in-
cluding relative position prediction (Doersch et al., 2015), temporal shuffling (Misra et al., 2016)
and contrastive predictive coding (Van den Oord et al., 2018). Mohsenvand et al. (2020) designs
data augmentation methods, and extends the self-supervised model SimCLR (Chen et al., 2020) in
computer vision to EEG data. In contrast to the numerous works investigating EEG, few studies
focus on SEEG data. Martini et al. (2021) proposes a self-supervised learning model for real-time
epilepsy monitoring in multimodal scenarios with SEEG data and video recordings.

Despite the advances on representation learning of brain signals, two main issues remain to be
overcome. Firstly, almost all existing methods are designed for a particular type of brain signal data,
and there is a lack of a unified method for handling both EEG and SEEG data. The challenge mainly
lies in the different clinical patterns of brain signals that need to be measured in different ways. On
the one hand, EEG collects noisy and rough brain signals on the scalp; differently, SEEG collects
deeper signals with more stereo spatial information, which indicates more significant differences
of different brain areas (Perucca et al., 2014). On the other hand, in contrast to EEG with a gold-
standard collection location, the monitoring areas of SEEG vary greatly between patients, leading
to different number and position of channels. Therefore, how to find the commonalities of EEG and
SEEG data to design a unified framework is challenging.

Another issue is about the gap between existing methods and the real-world applications. In clinical
scenarios, doctors typically locate brain lesions by analyzing signal patterns of each channel and
their holistic correlations. A straight-forward way for this goal is to model each of the channels sep-
arately by single-channel time series models, which, however, cannot exploit correlations between
brain areas (Davis et al., 2020; Lynn & Bassett, 2019). As for the existing multivariable time series
models, most of them can only capture implicit correlation patterns (Zerveas et al., 2021; Chen &
Shi, 2021), whereas explicit correlations are required by doctors for identifying lesions. Moreover,
although some graph-based methods have been proposed to explicitly learn correlations, they focus
on giving an overall prediction for all channels at a time but overlook the prediction on one specific
channel (Zhang et al., 2022; Shang et al., 2021). Therefore, how to explicitly capture the spatial and
temporal correlations while giving channel-wise prediction is another issue to be overcome.

In this paper, our main contribution is to propose a multi-channel self-supervised learning framework
MBrain, which can be generally applied for learning representations of both EEG and SEEG data. In
addition, we pay special attention to its application in seizure detection. Based on domain knowledge
and data observations, we propose to learn the correlation graph between channels as the common
cornerstone for both two types of brain signals. In particular, we employ Contrastive Predictive
Coding (CPC) (Van den Oord et al., 2018) as the backbone model of our framework by extending
it for handling multi-channel data with theoretically guaranteed effectiveness. Based on the multi-
channel CPC, we propose the instantaneous time shift task to learn the spatial correlations between
channels, and the delayed time shift task and the replace discriminative task are designed to capture
the temporal correlation patterns and to preserve the characteristics of each channel respectively.
Extensive experiments show that MBrain outperforms several state-of-the-art baselines on large-
scale real-world EEG and SEEG datasets for the seizure detection task.

2 PRELIMINARY: THEORETICAL ANALYSIS OF MULTI-CHANNEL CPC

We employ Contrastive Predictive Coding (CPC) (Van den Oord et al., 2018) as the basis of our
framework. The pretext task of CPC is to predict low-level local representations by high-level
global contextual representations ct at the t-th time step. Theoretically, the optimal InfoNCE
loss proposed by CPC with N − 1 negative samples Lopt
N is a lower bound of the mutual in-
formation between contextual semantic distribution p(ct) and raw data distribution p(xt+k), i.e.,
Lopt
N ≥ −I(xt+k; ct) + log N , where k is the prediction step size. CPC is originally designed for
single-channel sequence data only, and there are two natural ways to extend single channel CPC to
multi-channel version. The first one is to use CNNs with multiple kernels to encode all channels
simultaneously, which cannot offer explicit correlation patterns for doctors to identify lesions. The
second one is to train a shared CPC regarding all channels as one, which has no ability to capture
the correlation patterns. Taking a comprehensive consideration, we propose multi-channel CPC in
this paper. Our motivation is to explicitly aggregate the semantic information of multiple channels

2

Under review as a conference paper at ICLR 2023

to predict the local representations of one channel. Formally, we propose the following proposition
as our basic starting point.
Proposition 1. Introducing the contextual information of the correlated channels increases the
amount of mutual information with the raw data of the target channel.
t }j̸=i)) ≥ I(xi
t+k; Φ(ct)) = I(xi

(1)
where i and j are indexes of the channels. Φ(·) represents some kinds of aggregate function, which
has no additional formal constraints other than the need to retain information of the target channel.

t, Φ({cj

t+k; ci

t+k; ci

I(xi

t),

Proof. We use the linear operation of mutual information to obtain: I(xi
I(xi
t }j̸=i)|ci
information, we complete the proof.

t }j̸=i)) =
t). According to the non-negativity of the conditional mutual

t+k; Φ({cj

t) + I(xi

t+k; ci

t+k; ci

t, Φ({cj

It seems natural that the predictive ability of multiple channels is stronger than that of a single
channel, which is also consistent with the assumption of Granger causality (Granger, 1969) to some
extent. Therefore, we choose to approximate the more informative I(xi
t+k; Φ(ct)) to obtain more
expressive representations. Specifically, followed by InfoNCE, we define our loss function LN as

LN = −

(cid:88)

i

(cid:34)

EX i

log

fk(xt+k, Φ(ct))
xj ∈X fk(xj, Φ(ct))

(cid:80)

(cid:35)

,

(2)

where X i denotes the data sample set consisting of one positive sample and N − 1 negative samples
of the i-th channel. We then establish the relationship between LN and I(xi
Theorem 1. Given a sample set for each channel X i = {xi
one positive sample from p(xi
is the number of channels. The optimal Lopt

N }, i = 1, . . . , n consisting of
t+k)/n, where n

t+k|Φ(ct)) and N − 1 negative samples from (cid:80)
N is the lower bound of (cid:80)
t+k; Φ(ct)) + log N (cid:3) .
(cid:2)−I(xi

j p(xj
t+k; Φ(ct)):

t+k; Φ(ct)).

1, . . . , xi

i I(xi

Lopt

(cid:88)

(3)

N ≥

i

Proof. The optimal fk(xt+k, Φ(ct)) is proportional to p(xi
t+k)/n), which is
the same as single-channel CPC. And we can directly replace the data distributions in the proof of
single-channel CPC (see details in Appendix B) to obtain the inequality below:
(cid:35)
(cid:80)

(cid:80)

t+k|Φ(ct))/((cid:80)

j p(xj

(cid:34)

(cid:35)

(cid:35)

Lopt

N ≥

(cid:88)

i

EX i log

(cid:34) 1
n
p(xi

j p(xj
t+k)
t+k|Φ(ct))

+ log N

= EX 1,X 2,...,X n log

(cid:34) [ 1
n
Πjp(xj

j p(xj
t+k)]n
t+k|Φ(ct))

+n log N.

According to the Jensen Inequality, we obtain that ((cid:80)
exponentiating the two equations, we have

j log p(xj

t+k))/n ≤ log ((cid:80)

j p(xj

(4)
t+k)/n). By

Πjp(xj

t+k) ≤ [

1
n

(cid:88)

j

p(xj

t+k)]n.

(5)

With the help of equation 5, we can further obtain the lower bound of equation 4:
t+k)
t+k|Φ(ct))

Lopt
N ≥ EX 1,X 2,...,X n log

+ n log N =

(cid:2)−I(xi

Πjp(xj

Πjp(xj

(cid:88)

(cid:34)

(cid:35)

i

t+k; Φ(ct)) + log N (cid:3) . (6)

Then we complete the proof.

t+k; Φ(ct)), if the optimal loss function for each channel has log N gap with I(xi

We next analyze the advantages of multi-channel CPC over single-channel CPC. Our loss function
LN leads to a better predictive representation because we approximate a more informative objective
I(xi
t+k; Φ(ct)),
which is the same in single-channel CPC. Moreover, with the same GPU memory, the more channels,
the smaller the batch size that can be accommodated. But we can randomly sample negative samples
across all channels, which increases the diversity of negative samples. However, in order to narrow
the approximation gap, equation 5 should be considered. The equality sign in this inequality holds
if and only if samples from each channel follows the same distribution. In fact, for many large-
scale multi-channel time series data (e.g., brain signal data used in this paper), by normalizing each
channel, they all exhibit close normal distributions leading to small gaps in equation 5.

3

Under review as a conference paper at ICLR 2023

3 PROPOSED METHOD

In this section, we introduce the details of our proposed self-supervised learning framework MBrain.
For the commonality between EEG and SEEG, we are inspired by the synergistic effect of brain
that is, different connectivity patterns correspond to different brain
function and nerve cells,
states (Lynn & Bassett, 2019). In particular, for brain signals, nerve cells will spontaneously gener-
ate traveling waves and spread them out (Davis et al., 2020), maintaining some characteristics such
as shape during the process. Therefore, the degree of channel similarity implies different propaga-
tion patterns of traveling waves, reflecting the differences in connectivity patterns to some extent.
Both EEG and SEEG brain signals follow the inherent physiological mechanism. Therefore, we pro-
pose to extract the correlation graph structure between channels (brain areas) as the cornerstone of
unifying EEG and SEEG data (Section 3.1). Next, we introduce three self-supervised learning tasks
to model brain signals in Section 3.2. We propose instantaneous time shift task based on multi-
channel CPC and delayed time shift task to capture the spatial and temporal correlation patterns.
Then Replace discriminative task is further designed to preserve characteristics of each channel.

Notations. For both EEG and SEEG data, there are multiple electrodes with C channels. We use
X = {xl ∈ RC}L
l=1 to represent raw time series data with L time points. i and j denote the index
of channels. Yl,i ∈ {0, 1} is the label for the l-th time point and i-th channel. We use a W-length
window with no overlap to obtain the time segments S = {st}|S|
t=1 (see details in Appendix A). The
label corresponding to the t-th time segment and the i-th channel is denoted as Y s
t,i.

3.1 LEARNING CORRELATIONS BETWEEN CHANNELS

As mentioned above, the correlation patterns between different brain areas can help us to distin-
guish brain activities in downstream tasks to a large extent. Taking the seizure detection task as an
example, when seizures occur, more rapid and significant propagation of spike-and-wave discharges
will appear (Proix et al., 2018), which greatly enhances the correlation between channels. This phe-
nomenon is also verified by data observations in Appendix C, which supports us to treat correlation
graph structure learning as the common cornerstone of our framework. However, correlations be-
tween brain regions are difficult to be observed and recorded directly. Therefore, for each time step
t, our goal is to learn the structure of the correlation graph, whose adjacency matrix is At, where
nodes in the graph indicate channels and weighted edges denote the correlations between channels.

Considering that the brain is in normal and stable state most of the time, we first define the coarse-
grained correlation graph as the prior graph for a particular individual as

Acoarse(i, j) = Est[Cosine(st,i, st,j)],
where the expectation operation averages over all the correlation matrices computed in only one
time segment st, and Cosine(·, ·) denotes the cosine similarity function.
Next, based on Acoarse, for each pair of channels, we further model their fine-grained short-term cor-
relation within each time segment. We assume that the fine-grained correlations follow a Gaussian
distribution element-wise, whose location parameters are elements of Acoarse and scale parameters
will be learned from the data. By means of the reparameterization trick, the short-term correlation
matrix of the t-th time segment is sampled from the learned Gaussian distribution:

(7)

σt(i, j) = SoftPlus(MLP(cself
nt(i, j) ∼ N (0, 1),

t,τ,i, cself

t,τ,j)),

Afine
t

(i, j) = Acoarse(i, j) + σt(i, j) × nt(i, j).

(8)

(9)

(10)

SoftPlus(·) is a commonly used activation function to ensure the learned standard deviation is posi-
tive. cself
t,τ is the contextual representation of raw time segments extracted by encoders (see details in
Section 3.2). To remove the spurious correlations caused by low frequency signals and enhance the
sparsity, which is a common assumption in neuroscience (Yu et al., 2017), we filter the edges by a
threshold-based function to obtain the final correlation graph structure At:
(cid:40)

At(i, j) =

(11)

Afine
t
Afine
t

(i, j) ≥ θ1,
(i, j) < θ1.

Afine
t

(i, j),

0,

4

Under review as a conference paper at ICLR 2023

Figure 1: Overview of MBrain. The leftmost is the raw multi-channel brain signals. We use an
encoder to map the raw data into a low-dimensional representation space. To capture the spatial and
temporal correlation patterns, we propose three SSL tasks to guide the encoder to learn informative
and distinguishable representations.

3.2 SELF-SUPERVISED LEARNING TASKS FOR BRAIN SIGNALS

To capture the correlation patterns in space and time, we propose two self-supervised tasks: in-
stantaneous time shift that is based on multi-channel CPC and captures the short-term correlations
focusing on spatial patterns; and delayed time shift for temporal patterns in broader time scales.

Instantaneous Time Shift. For spatial patterns, we aim to leverage the contextual information of
correlated channels to better predict future data of the target channel. Therefore, we apply multi-
channel CPC and utilize the fine-grained graph structure At obtained in Section 3.1 as the correla-
tions between channels.

We first use a non-linear encoder genc (1D-CNN with d kernels) mapping the observed time seg-
ments to the local latent d-dimensional representations zt = genc(st) ∈ RT ×C×d for each channel
separately. T is the sequential length after down sampling by genc. Then an autoregressive model
gar is utilized to summarize the historical τ -length local information of each channel itself to obtain
the respective contextual representations:

cself
t,τ = gar(zt,1, · · · , zt,τ ).

(12)

In this step, we only extract the contextual information of all channels independently. Based on the
graph structure At, we instantiate the aggregate function Φ(·) in equation 4 as GNNs due to their
natural message-passing ability on a graph. Here we use a one-layer directed GCN (Yun et al., 2019)
to show the process:

cother
t,τ,i = ReLU

(cid:32) (cid:80)

j̸=i At(i, j) · cself
t,τ,j
(cid:80)
j̸=i At(i, j)

(cid:33)

· Θ

,

(13)

where Θ is the learnable matrix. Considering that we only aggregate other channels’ information,
the self-loop in GCN is removed here. Finally, by combining both cself
to obtain the global
representations ct,τ , the model can predict the local representations k1-step away zt,τ +k1 based on
the multi-channel CPC loss:

t,τ and cother
t,τ

t,τ , cother
ct,τ = Concat(cself
t,τ ),
(cid:34)
c⊤
t,τ,iWk1 zt,τ +k1,i
(cid:80)
c⊤
t,τ,iWk1 zj

log

L1 = LN = −Et,i,k1

zj ∈X i
t

(cid:35)

,

(14)

(15)

where X i
samples. Wk1 is the learnable bilinear score matrix of the k1-th step prediction.

t denotes the random noise set including one positive sample zt,τ +k1,i and N − 1 negative

5

Under review as a conference paper at ICLR 2023

Delayed Time Shift. For brain areas far apart, there exists delayed brain signal propagation, which
is confirmed by the data observations showed in Appendix C. We should consider these significant
temporal correlations across several time steps in our model.

Our motivation is that if a simple classifier can easily predict whether two time segments are highly
correlated, the segment representations will be significantly different from those with weaker cor-
relations. We thus define the delayed time shift task to encourage more distinguishable segment
representations. Similar with instantaneous time shift, we first compute the cosine similarity matrix
based on raw data between time segments across several time steps. For the i-th channel in the t-th
time segment, the long-term correlation matrix Bi

t is computed as
t(k2, j) = Cosine(st,i, st+k2,j),
where j traverses all channels including the target channel and k2 traverses at most K2 prediction
t according to Bi
steps. Then we construct pseudo labels Y i
t to encourage the segment representations
with higher correlations to be closer. A predefined threshold θ2 is set to assign pseudo labels:

(16)

Bi

Y i
t (k2, j) =

(cid:40)

1,

0,

Bi
Bi

t(k2, j) ≥ θ2,
t(k2, j) < θ2.

(17)

With the pseudo labels, we define the cross entropy loss of the delayed time shift prediction task:

ht = Pooling(cself

t,1 , · · · , cself

t,T ),

ˆp = Softmax(MLP(Concat(ht,i, ht+k2,j))),

(18)

(19)

L2 = −Et,i,k2,j

t (k2, j) log ˆp + (1 − Y i
where ˆp is the predicted probability that the two segments are highly correlated. In practical appli-
cation, we randomly choose 50% labels from each Y i

t (k2, j)) log(1 − ˆp)(cid:3)

t for efficient training.

(cid:2)Y i

(20)

Replace Discriminative Learning. Consistently exploiting correlation for all channels will weaken
the specificity between channels. However, there are significant differences in the physiological
signal patterns of different brain areas recorded by channels. Therefore, retaining the characteristics
of each channel cannot be ignored for the modeling of brain signals. For this purpose, we further
design the replace discriminative learning task.

Following BERT (Devlin et al., 2018), we randomly replace r% local representations throughout zt
by ˆzt, which is sampled from any T sequences and any C channels in zt. We use the notation I(ˆzt)
to represent the new local representations after replacement and the corresponding channel indexes
of ˆzt in the original sequence. We generate pseudo labels Yt of the task as below:

Yt(τ, i) =

(cid:26)1,
0,

I(ˆzt,τ,i) ̸= i,
I(ˆzt,τ,i) = i.

(21)

τ and i traverse T sequences and C channels of ˆzt. After obtaining ˆzt, we put it into the autoregres-
sive model to get the new contextual representations ˆct = gar(ˆzt). Finally, a simple discriminator
implemented by an MLP is utilized to classify whether ˆct are replaced by other channels or not:
L3 = −Et,τ,i [Yt(τ, i) log ˆq + (1 − Yt(τ, i)) log(1 − ˆq)] ,
where ˆq is the predicted probability that ˆct,τ,i is replaced. When the accuracy of discrimination
increases, different channel representations output by the autoregressive model are easier to distin-
guish. Therefore, the task preserves the unique characteristics of each channel.

(22)

Combining the multi-task loss functions equation 15, equation 20 and equation 22, we jointly train
MBrain with L = (1−λ1 −λ2)L1 +λ1L2 +λ2L3. After the SSL stage, the segment representations
ht obtained from equation 18 are used for downstream tasks.

4 EXPERIMENTS

4.1 DATASETS AND BASELINES

SEEG dataset. The SEEG dataset used in our experiment is anonymized and provided by a first-
class hospital we cooperate with. For a patient suffering from epilepsy, 4 to 10 invasive electrodes

6

Under review as a conference paper at ICLR 2023

with 52 to 124 channels are used for recording signals. It is worth noting that since SEEG data are
collected in a high frequency (1,000Hz or 2,000Hz) through multiple channels, our data is massive.
In total, we have collected 470 hours of SEEG signals with a total capacity of 550GB. Professional
neurosurgeons help us label the epileptic segments for each channel. For the self-supervised learn-
ing stage, we randomly sample 5,000 10-second SEEG clips for training and validation. As for the
downstream seizure detection task, we first obtain 5,000 sampled 10-second SEEG clips (80% for
training and 20% for validation). For the testing, we sample another 2,550 10-second SEEG clips
with positive and negative sample ratio of 1:50. We use a 1-second window to segment each clip
without overlap and our target is to make predictions for all channels in each 1-second segment.

EEG dataset. We use the Temple University Hospital EEG Seizure Corpus (TUSZ) v1.5.2 (Shah
et al., 2018) as our EEG dataset. It is the largest public EEG seizure database, containing 5,612 EEG
recordings, 3,050 annotated seizures from clinical recordings, and eight seizure types. We include
19 EEG channels in the standard 10-20 system. For experimental efficiency, we generate a smaller
dataset from TUSZ. We randomly sample 3,000 12-second EEG clips for self-supervised learning.
As for the downstream seizure detection task, we first obtain 3,000 sampled 12-second EEG clips
(80% for training and 20% for validation). For the testing, we sample another 3,900 12-second EEG
clips with positive and negative sample ratio of 1:10. It is worth noting that the labels of EEG data
are coarse-grained, which means we only have the label of whether epilepsy occurs in an EEG clip.

Baselines. We compare MBrain with state-of-the-art models including one supervised time se-
ries classification model MiniRocket (Dempster et al., 2021) and several self-supervised and un-
supervised models: CPC (Van den Oord et al., 2018), SimCLR (Chen et al., 2020), Triplet-
Loss (T-Loss) (Franceschi et al., 2019), Time Series Transformer (TST) (Zerveas et al., 2021),
GTS (Shang et al., 2021), TS-TCC (Eldele et al., 2021) and TS2Vec (Yue et al., 2021). See details
of the baselines in Appendix E.

4.2 EXPERIMENTAL SETUP

To demonstrate the effectiveness of MBrain, we first define the seizure detection task and perform
the experiments on EEG and SEEG datasets respectively. To examine the generalization of our
model, we further conduct experiments corresponding to two clinically feasible schemes on SEEG
dataset. The ablation study, hyperparameter analysis, variance and more experimental results are
showed in Appendix G, H and I. We also show the case study of the correlation graph learned by
Section 3.1 in Appendix F to confirm the ability of identifying different brain states.

Task 1 (Seizure Detection). Given a time-ordered set including IS consecutive time segments with
the index of the first segment being t0: S = {st0, . . . , st0+IS }, models predict the labels ˆY s
t,i for all
time segments in S (i.e., t = t0, . . . , t0 + IS ) and all channels in each segment (i.e., i = 1, . . . , C).

Seizure detection experiment.
In this experiment, we first perform the self-supervised learning
of the model on unlabeled data. Then the segment representations learned by the model are used
for downstream seizure detection task (see details in Appendix D). During the training phase of
downstream task, the encoder of SSL model will be fine-tuned with a very low learning rate. For
EEG data, there is no overlap between the patients of training and testing sets. In addition, since EEG
labels are coarse-grained, the segment representations in each 12-second EEG clip are pooled to one
representation and then be used for seizure detection. For SEEG data, considering the difference
in the number and location of implanted electrodes for patients, we conduct experiments for each
patient independently and report the average performance.

Transfer learning experiments. To meet practical clinical needs, we design two clinically feasible
schemes for SEEG data. The first is the domain generalization experiment, that is, training the
model on data of existing patients and directly predicting data of unknown patients. More specif-
ically, we follow the “3-1-1” setting, where 3 patients are used for training, 1 patient is used for
validation and 1 patient is used for testing. We conduct experiments for all combinations, pick up
the best result for each patient, and report the average results over all patients. The second is the
domain adaptation experiment (Motiian et al., 2017). In this experiment, we first perform SSL
on one patient (i.e., source domain) and then fine-tuning is performed using partial labeled data from
another patient (i.e., target domain) in the testing set. Finally, we perform seizure detection on the

7

Under review as a conference paper at ICLR 2023

remaining data of the target domain. We report the results on 12 cross-domain scenarios covering
all combinations of four patients with typical seizure patterns in the SEEG dataset.

4.3 RESULTS OF SEIZURE DETECTION EXPERIMENT

The average performance of seizure detection on the SEEG dataset are presented in Table 1. Since
the positive-negative sample ratio of SEEG dataset is imbalanced, F -score is a more appropriate
metric to evaluate the performance of models than only considering precision or recall. Especially
in clinical applications, doctors pay more attention to finding as much seizures as possible, we thus
choose F1-score and F2-score in the experiment. Overall, MBrain improves the F1-score by 28.92%
and the F2-score by 26.85% on SEEG dataset compared to the best result of baseline methods,
demonstrating that MBrain can learn informative representations from SEEG data.

Table 1: The average performance of the seizure detection experiment on SEEG and EEG datasets.

Models

Pre.

MiniRocket

22.98

CPC
SimCLR
T-Loss
TST
GTS
TS-TCC
TS2Vec

MBrain

27.65
11.06
29.29
13.60
24.29
22.10
30.56

37.97

SEEG

Rec.

66.24

55.07
51.54
51.55
44.65
40.39
49.94
52.83

65.07

F1
31.79

34.20
16.60
36.00
19.80
29.16
25.32
36.03

F2
43.58

42.73
25.41
43.13
28.41
34.17
32.74
43.35

46.45

55.28

Pre.

Rec.

22.86

63.08

58.31
74.88
69.25
28.59
62.51
39.76
58.31

22.81
12.63
20.72
15.65
18.86
15.55
21.40

22.13

EEG

F1
33.56

32.50
21.33
31.82
19.65
28.88
21.89
31.24

F2
46.66

44.02
36.78
47.00
23.87
42.54
29.60
43.24

76.99

34.32

51.34

AUROC

75.30

74.53
55.86
75.88
58.20
71.69
58.63
73.35

77.96

Table 1 also shows the results of seizure detection experiment on EEG dataset. Following the com-
mon evaluation scheme on EEG dataset (Tang et al., 2022), we also add Area Under the Receiver
Operating Characteristic (AUROC) metric in our experiment. Our model is designed to learn the
representation for each channel, while there is only one label for an EEG clip. Therefore, it requires
the pooling operation to aggregate representations output by our model over channels and time seg-
ments for seizure detection. This setting makes the performance improvement of our model not as
significant as that in the SEEG experiment. Nevertheless, MBrain still outperforms all baselines on
F1-score, F2-score and AUROC with an increase of 2.26%, 9.23% and 2.74%, respectively.

Table 2: The average performance of the domain generalization experiment on SEEG dataset.

Models

CPC
T-Loss
TS2Vec

MBrain

Pre.

Rec.

22.88±5.06
21.38±4.25
27.93±5.23

23.92±3.90
28.50±4.07
29.49±3.97

F1
20.11±3.27
23.48±3.30
26.78±3.29

F2
21.23±2.49
25.90±3.06
27.88±3.52

30.69±5.92

38.94±4.34

32.61±3.60

35.64±3.04

4.4 RESULTS OF DOMAIN GENERALIZATION EXPERIMENT

In this experiment, we compare the baseline models that perform well in Table 1. This is because,
to some extent, the results in Table 1 represent an upper bound on the performance of these models.
We point out that although GTS and MBrain are both graph-based models, GTS cannot be trained on
multiple patients, since the DCRNN (Li et al., 2018) encoder used in GTS can only process graphs
with fixed nodes. In contrast, our model is designed to learn the correlations between each pair of
nodes and utilizes inductive GNN, so it can easily handle graphs with different numbers of input
nodes. In general, the performance of models under the domain generalization setting decreases
significantly (40.37% on average in terms of F2-score) compared with that in epilepsy detection

8

Under review as a conference paper at ICLR 2023

experiment. The drop for recall metric is more pronounced, confirming that the distribution shift of
patients in SEEG data is more significant than that in EEG. This results from the fact that differ-
ent brain regions and different types of epileptic waves have different physiological properties and
patterns. MBrain in this experiment still improves F1-score and F2-score by 21.77% and 27.83%
respectively, compared to the best baseline. The results prove that MBrain has a superior general-
ization ability benefiting from rational inductive assumption of model design.

Table 3: The performance of the domain adaptation experiment on SEEG dataset in terms of F2-
score. DA row denotes the performance of MBrain in the domain adaptation experiment setting.
Max-base and Non-DA rows represent the best performance of baselines and MBrain in the seizure
detection experiment. Bold numbers and * indicate the best and the second best performance.

Setting

DA
Max-base
Non-DA

Group A

Group B

Group C

Group D

B→A C→A D→A A→B C→B D→B A→C B→C D→C A→D B→D C→D

68.55 69.14* 68.78 41.08 46.06 46.12* 40.04 39.34 48.64 80.82* 79.90 80.72

62.49
70.63

39.78
46.62

33.59
46.09*

75.35
83.27

4.5 RESULTS OF DOMAIN ADAPTATION EXPERIMENT

According to the results of domain generalization experiment, it is difficult for MBrain to achieve
competitive performance with Table 1. Due to the long record, clinical SEEG data contains tens
or even hundreds of seizures, allowing our model to use a subset of data to fine-tune and then to
predict the remaining data. Therefore, as a clinical alternative to domain generalization, we con-
duct a compromise domain adaptation experiment. Table 3 shows the performance of the domain
adaptation (DA) experiment for four patients with typical seizure patterns provided by doctors from
SEEG dataset. More specifically, we train MBrain on one patient and fine-tune it on all other three
patients. B→A denotes that the SSL model is trained on Patient-B and then performs seizure de-
tection experiment with the SSL model being fine-tuned on Patient-A. The results of “Max-base”
and “Non-DA” rows correspond to the performance of the best baseline and MBrain respectively in
scenarios A→A, B→B, C→C and D→D.

Compared with the results in the condition that the self-supervised model and downstream model
are both trained on the same patient, the F2-scores of all 12 cross-domain scenarios reduce by less
than 15%. Additionally, it can be observed that in all cross-domain scenarios, MBrain beats the
It is worth noting that
best baseline in the corresponding scenarios without domain adaptation.
D→C scenario outperforms corresponding “Non-DA” result. The possible reason is that the signal
patterns on Patient-D are more significant and recognizable than those on Patient-C. Therefore,
the SSL model trained on higher quality source domain can better distinguish signal states when
performing downstream tasks on target domain. Overall, the domain adaptation experiment makes
MBrain achieve competitive performance with Table 1 by fine-tuning it on only a subset of the target
domain. The results suggest that MBrain captures the inherent features and outputs generalized
representations between patients, because we fine-tune the SSL model with a very low learning rate
(1e-6). From the perspective of pre-training, the SSL model trained on the source patient gives good
initial parameters for the fine-tuning stage on the target patient.

5 CONCLUSION AND DISCUSSION

In this paper, we propose a general multi-channel SSL framework MBrain, which can be applied
for learning representations of both EEG and SEEG brain signals. Based on domain knowledge and
data observations, we succeed to use the correlation graph between channels as the cornerstone of
our model. The proposed instantaneous and delayed time shift tasks help us capture the correlation
patterns of brain signals spatially and temporally. Extensive experiments of seizure detection on
large-scale real-world datasets demonstrate the superior performance and generalization ability of
MBrain. However, there are still some limitations of our work. For example, negative sampling of
multi-channel CPC consumes certain memory and time. Besides, we lack a more automatic way to
determine the time range of long-term temporal patterns. As for the future work, we plan to collect
more types of brain signals and extend MBrain to more downstream tasks.

9

Under review as a conference paper at ICLR 2023

6 REPRODUCIBILITY STATEMENT

We provide the source code of our model MBrain in the Supplementary Material. Some implemen-
tation details of MBrain can be found in Appendix D and default hyperparameters can be found in
the code. Users can run MBrain on their own datasets, following the same generation method of
database mentioned in Section 4.1.

7 ETHICS STATEMENT

This paper proposes a novel self-supervised learning framework MBrain for brain signals, and con-
duct experiments on real-world large-scale EEG and SEEG datasets. The EEG dataset is public and
SEEG dataset is non-public but anonymous. Overall, this work inherits some of the risks of the ex-
isting works implementing the EEG dataset and does not introduce any new ethical or future social
concerns for SEEG dataset.

REFERENCES

Fahd A. Alturki, Khalil AlSharabi, Akram M. Abdurraqeeb, and Majid Aljalal. Eeg signal analysis
for diagnosing neurological disorders using discrete wavelet transform and intelligent techniques.
Sensors, 20(9), 2020.

Anthony Bagnall, Jason Lines, Aaron Bostrom, James Large, and Eamonn Keogh. The great time se-
ries classification bake off: A review and experimental evaluation of recent algorithmic advances.
Data mining and knowledge discovery, 31(3):606–660, 2017.

Hubert Banville, Omar Chehab, Aapo Hyv¨arinen, Denis-Alexander Engemann, and Alexandre
Gramfort. Uncovering the structure of clinical EEG signals with self-supervised learning. Journal
of Neural Engineering, 18(4):046020, 2021.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,
Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei. Language models are few-shot learners. In NIPS, pp. 1877–1901, 2020.

J. X. Chen, P. W. Zhang, Z. J. Mao, Y. F. Huang, D. M. Jiang, and Y. N. Zhang. Accurate eeg-
based emotion recognition on combined features using deep convolutional neural networks. IEEE
Access, 7:44317–44328, 2019.

Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for

contrastive learning of visual representations. In ICML, pp. 1597–1607, 2020.

Wei Chen and Ke Shi. Multi-scale attention convolutional neural network for time series classifica-

tion. Neural Networks, 136:126–140, 2021.

Xinlei Chen and Kaiming He. Exploring simple siamese representation learning.

In CVPR, pp.

15745–15753, 2021.

Alexander Craik, Yongtian He, and Jose L Contreras-Vidal. Deep learning for electroencephalogram

(eeg) classification tasks: a review. Journal of neural engineering, 16(3):031001, 2019.

Zachary W Davis, Lyle Muller, Julio Martinez-Trujillo, Terrence Sejnowski, and John H Reynolds.
Spontaneous travelling cortical waves gate perception in behaving primates. Nature, 587(7834):
432–436, 2020.

Angus Dempster, Franc¸ois Petitjean, and Geoffrey I Webb. Rocket: exceptionally fast and accu-
rate time series classification using random convolutional kernels. Data Mining and Knowledge
Discovery, 34(5):1454–1495, 2020.

10

Under review as a conference paper at ICLR 2023

Angus Dempster, Daniel F Schmidt, and Geoffrey I Webb. Minirocket: A very fast (almost) deter-

ministic transform for time series classification. In KDD, pp. 248–257, 2021.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsupervised visual representation learning by

context prediction. In ICCV, pp. 1422–1430, 2015.

Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, and
Cuntai Guan. Time-series representation learning via temporal and contextual contrasting.
In
IJCAI, pp. 2352–2359, 2021.

Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi. Unsupervised scalable representation

learning for multivariate time series. In NIPS, 2019.

Clive WJ Granger. Investigating causal relations by econometric models and cross-spectral methods.

Econometrica: journal of the Econometric Society, pp. 424–438, 1969.

Jean-Bastien Grill, Florian Strub, Florent Altch´e, Corentin Tallec, Pierre Richemond, Elena
Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar,
Bilal Piot, koray kavukcuoglu, Remi Munos, and Michal Valko. Bootstrap your own latent - a
new approach to self-supervised learning. In NIPS, pp. 21271–21284, 2020.

Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for

unsupervised visual representation learning. In CVPR, pp. 9726–9735, 2020.

Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural computation, 9:1735–

80, 1997.

Lina Elsherif Ismail and Waldemar Karwowski. Applications of eeg indices for the quantification of
human cognitive performance: A systematic review and bibliometric analysis. PloS one, 15(12):
e0242857, 2020.

Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.

Shiba Kuanar, Vassilis Athitsos, Nityananda Pradhan, Arabinda Mishra, and K.R. Rao. Cognitive
analysis of working memory load from eeg, by a deep recurrent neural network. In ICASSP, pp.
2576–2580, 2018.

Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural net-

work: Data-driven traffic forecasting. In ICLR, 2018.

Christopher W Lynn and Danielle S Bassett. The physics of brain network structure, function and

control. Nature Reviews Physics, 1(5):318–332, 2019.

Michael L Martini, Aly A Valliani, Claire Sun, Anthony B Costa, Shan Zhao, Fedor Panov, Saadi
Ghatan, Kanaka Rajan, and Eric Karl Oermann. Deep anomaly detection of seizures with paired
stereoelectroencephalography and video recordings. Scientific Reports, 11(1):1–11, 2021.

Ishan Misra, C Lawrence Zitnick, and Martial Hebert. Shuffle and learn: unsupervised learning

using temporal order verification. In ECCV, pp. 527–544. Springer, 2016.

Mostafa Neo Mohsenvand, Mohammad Rasool Izadi, and Pattie Maes. Contrastive representation

learning for electroencephalogram classification. In PMLR, pp. 238–253, 2020.

Saeid Motiian, Marco Piccirilli, Donald A Adjeroh, and Gianfranco Doretto. Unified deep super-

vised domain adaptation and generalization. In ICCV, pp. 5715–5725, 2017.

M. Paluszek, D. Avirovik, Y. Zhou, S. Kundu, A. Chopra, R. Montague, and S. Priya. 11 - mag-
netoelectric composites for medical application. In Composite Magnetoelectrics, pp. 297–327.
Woodhead Publishing, 2015.

11

Under review as a conference paper at ICLR 2023

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-
performance deep learning library. Advances in neural information processing systems, 32, 2019.

Piero Perucca, Franc¸ois Dubeau, and Jean Gotman. Intracranial electroencephalographic seizure-

onset patterns: effect of underlying pathology. Brain, 137(1):183–196, 2014.

Timoth´ee Proix, Viktor K Jirsa, Fabrice Bartolomei, Maxime Guye, and Wilson Truccolo. Predict-
ing the spatiotemporal diversity of seizure propagation and termination in human focal epilepsy.
Nature communications, 9(1):1–15, 2018.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi
Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text
transformer. Journal of Machine Learning Research, 21(140):1–67, 2020.

Khansa Rasheed, Adnan Qayyum, Junaid Qadir, Shobi Sivathamboo, Patrick Kwan, Levin
Kuhlmann, Terence O’Brien, and Adeel Razi. Machine learning for predicting epileptic seizures
using eeg signals: A review. IEEE Reviews in Biomedical Engineering, 14:139–155, 2020.

Patrick Sch¨afer. The boss is concerned with time series classification in the presence of noise. Data

Mining and Knowledge Discovery, 29(6):1505–1530, 2015.

Vinit Shah, Eva Von Weltin, Silvia Lopez, James Riley McHugh, Lillian Veloso, Meysam Gol-
mohammadi, Iyad Obeid, and Joseph Picone. The temple university hospital seizure detection
corpus. Frontiers in Neuroinformatics, 12:83, 2018.

Chao Shang, Jie Chen, and Jinbo Bi. Discrete graph structure learning for forecasting multiple time

series. In ICLR, pp. 1–14, 2021.

Afshin Shoeibi, Marjane Khodatars, Navid Ghassemi, Mahboobeh Jafari, Parisa Moridian, Roohal-
lah Alizadehsani, Maryam Panahiazar, Fahime Khozeimeh, Assef Zare, Hossein Hosseini-Nejad,
et al. Epileptic seizures detection using deep learning techniques: a review. International Journal
of Environmental Research and Public Health, 18(11):5780, 2021.

Tengfei Song, Wenming Zheng, Peng Song, and Zhen Cui. Eeg emotion recognition using dy-
namical graph convolutional neural networks. IEEE Transactions on Affective Computing, 11(3):
532–541, 2020.

Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, and Geoffrey I Webb. Monash university,

uea, ucr time series regression archive. arXiv preprint arXiv:2006.10996, 2020.

Siyi Tang, Jared Dunnmon, Khaled Kamal Saab, Xuan Zhang, Qianying Huang, Florian Dubost,
Daniel Rubin, and Christopher Lee-Messer. Self-supervised graph neural networks for improved
electroencephalographic seizure analysis. In ICLR, 2022.

Aaron Van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-

tive coding. arXiv e-prints, 2018.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,

Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, 2017.

Renping Yu, Han Zhang, Le An, Xiaobo Chen, Zhihui Wei, and Dinggang Shen. Connectivity
strength-weighted sparse group representation-based brain network construction for m ci classifi-
cation. Human brain mapping, 38(5):2370–2383, 2017.

Ye Yuan, Guangxu Xun, Kebin Jia, and Aidong Zhang. A multi-view deep learning framework for
eeg seizure detection. IEEE Journal of Biomedical and Health Informatics, 23(1):83–94, 2019.

Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong,
and Bixiong Xu. Ts2vec: Towards universal representation of time series. arXiv preprint
arXiv:2106.10466, 2021.

Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. Graph trans-

former networks. In NIPS, 2019.

12

Under review as a conference paper at ICLR 2023

George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty, and Carsten Eickhoff.
A transformer-based framework for multivariate time series representation learning. In KDD, pp.
2114–2124, 2021.

Xiang Zhang, Lina Yao, Xianzhi Wang, Jessica Monaghan, David Mcalpine, and Yu Zhang. A
survey on deep learning-based non-invasive brain signals: recent advances and new frontiers.
Journal of Neural Engineering, 18(3):031002, 2021.

Xiang Zhang, Marko Zeman, Theodoros Tsiligkaridis, and Marinka Zitnik. Graph-guided network
for irregularly sampled multivariate time series. In ICLR, 2022. URL https://openreview.
net/forum?id=Kwm8I7dU-l5.

Zhe Zhu. Change detection using landsat time series: A review of frequencies, preprocessing,
algorithms, and applications. ISPRS Journal of Photogrammetry and Remote Sensing, 130:370–
384, 2017.

13

Under review as a conference paper at ICLR 2023

A PRELIMINARIES

Brain signal data. For both EEG and SEEG data, there are multiple electrodes with C contacts that
are sampled at a fixed frequency to record the brain signals. We also call these contacts channels.
For every sampling point, each channel records the potential value of the brain region in which they
are located, constituting abstract multi-channel time series data. A complete record file contains
a total of L time points, for which we use the notation X = {xl ∈ RC}L
l=1 to represent. In the
reminder of this paper, we use i and j to denote the index of channels, such as xl = {xl,i}C
i=1.
For every xl,i, we assign a binary label Yl,i ∈ {0, 1} to it according to the start and end time of
epileptic brain signals marked by doctors. The time points are in the epileptic state with positive
labels (Yl,i = 1), while zero labels (Yl,i = 0) represent the normal data.

Preprocessing. Following the existing time series works (Zhu, 2017; Bagnall et al., 2017; Sch¨afer,
2015) with the common preprocessing of segmentation, we use a W-length window to divide the
original brain signal data X into time segments S = {st ∈ RW×C}|S|
t=1 without overlapping. The
number of segments |S| = ⌊L/W⌋. The segment label is obtained from the time points of the whole
segment, i.e., Y s

t,i = max{Yt×W+1,i, . . . , Y(t+1)×W,i}.

B SINGLE-CHANNEL CPC

Contrastive Predictive Coding (CPC), a pioneering model for self-supervised contrastive learning,
sets the pretext task to predict low-level local representations by high-level global contextual infor-
mation ct. In this way, the model can avoid learning too many details of the raw data and pay more
attention to the contextual semantic information of the sequence data. The InfoNCE loss proposed
in CPC has become the basic design of the contrastive learning loss function. Specifically, given
a raw data sample set X = {x1, . . . , xN } consisting of one positive sample from p(xt+k|ct) and
N − 1 negative samples from the noisy distribution p(xt+k), InfoNCE will optimize:
(cid:34)

(cid:35)

LN = −EX

log

(cid:80)

fk(xt+k, ct)
xj ∈X fk(xj, ct)

.

(23)

In order to obtain the best classification probability of the positive sample with the cross entropy loss
function, the optimal fk(xt+k, ct) is proportional to p(xt+k|ct)/p(xt+k). Furthermore, the optimal
loss function is also closely related to mutual information, as below:

(cid:34)

Lopt
N = −EX

log

(cid:20)

log

≥ EX

p(xt+k|ct)/p(xt+k) + (cid:80)
(cid:21)
p(xt+k)
p(xt+k|ct)

N

p(xt+k|ct)/p(xt+k)

xj ∈Xneg

p(xj|ct)/p(xj)

= −I(xt+k; ct) + log N.

(cid:35)

(24)

(25)

Therefore, we can conclude that while minimizing the loss function LN , we are also constantly
approximating the mutual information of raw data distribution p(xt+k) and contextual semantic
distribution p(ct). It turns out that InfoNCE is indeed a well-established loss function designed for
self-supervised contrastive learning.

C DATA OBSERVATIONS

As Figure 2 shows, for both EEG and SEEG data, we can observe that the correlation matrices are
almost the same on two normal segments without overlapping in the same patient. To the opposite,
the correlation matrix in the epileptic states differs from the normal ones greatly. These data ob-
servations verify the conclusion that correlation patterns can help us to distinguish different brain
states, and support us to use the correlation matrix as the cornerstone of EEG and SEEG data.

14

Under review as a conference paper at ICLR 2023

Figure 2: The normal and seizure correlation matrices of EEG and SEEG brain signals. The top
row is for SEEG and the bottom row is for EEG. For clear presentation, we sample some channels
in SEEG data. The leftmost column including two figures are the base correlation matrices on
normal data. The two figures in the middle column represent the matrices after subtracting another
normal correlation matrices from the base matrices, and the rightmost column includes matrices
after subtracting seizure correlation matrices from the base matrices.

Figure 3: The correlation matrices of delayed time shift of SEEG data. The top figure shows the
average correlation matrix over all 10-second SEEG clips of one particular patient. And the bottom
figure represents the correlation matrix of one particular sampled 10-second clip. We compute the
cosine similarity matrix between the first time segment in the clip of the first channel and the time
segments of other channels in the next consecutive 7 time steps. For clear presentation, we sample
26 channels and set correlations below 0.5 to 0 for the bottom figure.

The data observations showed in Figure 3 and Figure 4 confirm that there still exist significant cor-
relations between time segments across several time steps. Unlike instantaneous time shift, delayed
correlations are not stable. This can be concluded from the numerical difference between the aver-

15

Correlation matrices of delayed time shift (SEEG)ChannelsTemporal stepsUnder review as a conference paper at ICLR 2023

Figure 4: The correlation matrices of delayed time shift of EEG data. The top figure shows the
averaged correlation matrix over all 12-second EEG clips. And the bottom figure represents the
correlation matrix of one particular 12-second clip which is randomly sampled. The computation
and operation are the same as Figure 3.

aged correlation matrix and the one-clip correlation matrix in both figures. Therefore, we design a
self-supervised task different from that in the instantaneous time shift to learn the delayed correla-
tions.

D IMPLEMENTATION DETAILS OF MBrain

The non-linear encoder genc used in MBrain is composed of three 1-D convolution layers and a
one-layer LSTM model (Hochreiter & Schmidhuber, 1997) is used as the autogressive model gar.
The model is optimized using Adam optimizer (Kingma & Ba, 2015) with a learning rate of 2e-4
and weight decay of 1e-6 for the self-supervised learning stage. And for the downstream seizure
detection stage, the downstream model is optimized with a learning rate of 5e-4 and weight decay
of 1e-6 while the SSL model is fine-tuned with a low learning rate of 1e-6. For the hyperparameters
of MBrain, we set θ1 = 0.5 and θ2 = 0.5. We set the maximum value of k1 in instantaneous time
shift task as 8. As Figure 5 shows, we set K2 = 7 so as to take into account the step with the
most significant correlation in delayed time shift task. Lastly, we build our model using PyTorch
1.8 (Paszke et al., 2019) and trained it on a workstation with four NVIDIA TESLA T4 GPUs.

For the downstream task, we first utilize an LSTM model (Hochreiter & Schmidhuber, 1997) to
encode the segment representations of each channel in chronological order (10-second in SEEG
clips and 12-second in EEG clips) independently. One-layer self-attention (Vaswani et al., 2017) is
then adopted to all channels within the same time step. Finally, a two-layer MLP classifier is used to
predict whether epilepsy is occurring in the time segments. All baselines share the same downstream
model in our experiments.

E IMPLEMENTATION DETAILS OF BASELINES

• MiniRocket (Dempster et al., 2021): Rocket (Dempster et al., 2020) is a state of the art supervised
time series classification method based on evaluations on public benchmarks (Bagnall et al., 2017;
Tan et al., 2020), involves training a linear classifier on top of features extracted by a flat collection
of numerous and various random convolutional kernels. MiniRocket is a variant of Rocket which
improves processing time, while offering essentially the same accuracy. We uese the open source

16

Correlation matrices of delayed time shift (EEG)ChannelsTemporal stepsUnder review as a conference paper at ICLR 2023

Figure 5: The data observation of how to choose hyperparameter K2. We first average the correla-
tions of all channels of each channel in each time step. Then we average those of all channels in the
same time step. As the figure shows, we empirically choose K2 = 7.

code from https://github.com/angus924/minirocket. For each subject, we use the features obtained
through MiniRocket to train an independent logistic regression classifier for each channel and test
it on the test set of that channel.

• CPC (Van den Oord et al., 2018): This is a self-supervised learning method based on a contrastive
loss InfoNCE. The pretext task of CPC is set to predict future local low-level representations
obtained from multi-layer CNNs by contextual high-level representations obtained from an au-
toregressive model. This is the backbone model in this paper. We use the open source code of the
corrected version from https://github.com/facebookresearch/CPC audio.

• SimCLR (Chen et al., 2020): This is a simple yet effective framework for contrastive learning of
visual representations and we use time-series specific augmentations to adapt it to our application.
We implemented SimCLR on time series data by ourselves. We use the same encoder architecture
and parameter configuration as TS-TCC. In the meantime, we also follow TS-TCC and use scaling
(sigma=1.1) as the data augmentation way.

• Triplet-Loss (T-Loss) (Franceschi et al., 2019): The approach employs time-based negative
sampling and a triplet loss to learn representations for time series segments. We use the de-
fault model architecture from the source code provided by the author (https://github.com/White-
Link/UnsupervisedScalableRepresentationLearningTimeSeries). For the sampling method of neg-
ative samples, we use the data of the previous batch as the candidate set of negative samples of
the current batch data (the negative sample candidate set for the first batch is itself). Since the
dataloader is shuffled at the end of each epoch, there is no need to worry about the case where the
set of sampled negative samples does not change.

• Time Series Transformer (TST) (Zerveas et al., 2021): This is a unsupervised repre-
sentation learning framework for multivariate time series by training a transformer model
to extract dense vector representations of time series through an input denoising objec-
tive. We use the default model architecture from the source code provided by the author
(https://github.com/gzerveas/mvts transformer).

• GTS (Shang et al., 2021): This is a time series forecasting model that learns a graph structure
among multiple time series and forecasts them simultaneously with a GNN. In view of this, this
model can learn useful representations from unlabeled time series data. We use the default model
architecture from the source code provided by the author (https://github.com/chaoshangcs/GTS).
In the pre-training stage, we divide each time series segment into 10 parts on average, and learn a
time series forecasting model that predicts the next 2 steps based on the previous 8 steps. In the
downstream task stage, we use the representation after step 10 as the representation of the time
series segment for the seizure detection task.

• TS-TCC (Eldele et al., 2021): This is an unsupervised time-series representation learning frame-
work, applying a temporal contrasting module and a contextual contrasting module to learn robust

17

123456789Temporal steps0.0100.0050.0000.0050.010Cosine correlationsAnalysis of hyperparameter K2Under review as a conference paper at ICLR 2023

and discriminative representations. We use the default model architecture from the open source
code provided by the author (https://github.com/emadeldeen24/TS-TCC).

• TS2Vec (Yue et al., 2021): This is a universal representation learning framework for time series,
that applies hierarchical contrasting to learn scale-invariant representations within augmented con-
text views. We use the default model architecture from the source code provided by the author
(https://github.com/yuezhihan/ts2vec).

F CASE STUDY

(a) Normal correlation graph.

(b) Seizure correlation graph.

Figure 6: Case study on correlation graphs learned by MBrain.

In this section, we study the correlation graphs between the channels learned by MBrain. We ran-
domly sample normal and seizure SEEG clips of one particular patient, and visualize their cor-
relation graphs. The correlation graphs showed in Figure 6, we use the threshold θ1 defined in
Section 3.1 for the preservation of the edges. In addition, the thickness of an edge represents the
edge weight, and the size of a node represents the sum of the edge weights of all the edges linked to
that node. It can be observed that during the normal phase, the correlation is sparser and the weights
between edges are smaller, indicating a weaker correlation between channels. In contrast, during the
seizure phase, the pattern between channels varies, with the correlation becomes denser and the edge
weights become larger. Furthermore, in the correlation graph of the seizure phase, edges with larger
weights are usually connected to 2 seizure channels, like Channel-2, Channel-35 and Channel-38 in
Figure 6(b), which can help surgeons to better localize the seizure lesions.

G ABLATION STUDY

We study the effectiveness of each component in MBrain. Specifically, we compare MBrain with
different model variants removing following different components. We firstly remove the corre-
lation graph structure learning module from the instantaneous time shift task and degenerate the
task to single-channel CPC while still uniformly sampling negative samples in all channels. This
variant is denoted as “MBrain-Graph”. Next, we respectively remove the whole instantaneous time
shift task, the delayed time shift task and replace discriminative task. These model variants are de-
noted as “MBrain-Instant”, “MBrain-Delay” and “MBrain-Replace”. Finally, we consider the con-
dition of preserving only one self-supervised task. “MBrain-onlyInstant”, “MBrain-onlyDelay” and

18

01234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950510123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Under review as a conference paper at ICLR 2023

“MBrain-onlyReplace” indicate that MBrain only performs instantaneous time shift task, delayed
time shift task and replace discriminative task respectively.

We repeat the experiments five times in the fine-tuning stage of the downstream seizure detection
task. Table 4 shows the results of ablation study on SEEG dataset. It can be observed that the com-
plete MBrain achieves the best performance on F1 and F2 metrics, demonstrating the effectiveness
of each component in our model design. For “MBrain-Instant”, the significant decrease in perfor-
mance illustrates that capturing the spatial and short-term patterns is quite important and is the key
to learning the essential representations in multi-channel brain signals. For “MBrain-Graph”, the
decrease in performance demonstrates that multi-channel CPC can greatly help learn more infor-
mative representations. Additionally, the performance in “MBrain-Delay” and “MBrain-Replace”
also decreases significantly, illustrating that modeling long-term temporal patterns and preserving
the characteristics of channels can help learn more distinguishable representations. In the condition
where only one self-supervised task is preserved, it can be observed that the instantaneous time shift
task is the most important, which is as expected, and the delayed time shift task and the replace
discriminative task contribute similarly to the performance of the complete model.

Table 4: The results of ablation study.

Models

CPC
CPC-Conv
CPC-MLP

MBrain-Graph
MBrain-Instant
MBrain-Delay
MBrain-Replace

MBrain-onlyInstant
MBrain-onlyDelay
MBrain-onlyReplace

Pre.

Rec.

F1

F2

27.65±4.49
6.39±0.77
25.84±3.07

36.72±4.59
34.49±4.37
35.00±4.49
36.08±5.35

36.43±4.44
31.59±4.24
34.13±6.84

55.07±3.52
33.21±4.00
52.70±3.65

60.48±4.47
55.41±3.90
65.61±2.94
63.67±4.24

63.66±2.12
55.03±5.26
56.06±3.68

34.20±3.40
10.53±1.07
32.18±2.46

43.61±3.08
41.57±3.48
42.97±3.61
43.66±3.66

43.35±3.83
38.56±2.84
40.02±4.47

42.73±2.57
17.46±1.42
40.34±2.05

51.47±2.68
48.38±2.52
52.51±1.93
52.49±2.32

51.82±2.67
46.05±2.26
47.44±2.40

MBrain

37.97±2.75

65.07±2.68

46.45±2.25

55.28±1.77

In addition to removing some components and tasks from MBrain, we also design some ablation
experiments to verify the effectiveness of our proposed graph structure learning. We have proposed
two ideas on how to directly implement the multi-channel CPC in Section 2. For the second idea,
we have reported the results of a shared CPC regarding all channels as one on the CPC row of
Table 1. For the first idea, we design two strategies to combine multi-channel CNN or MLP into
CPC respectively to learn representations for each channel.

• Directly use 1-Dimension CNN to encode the whole time series data and the number of channels
during the process is C → 256 → 256 → C × 256, and split the output into C representations,
each of which is a 256-dimensional representation. Then an LSTM is implemented to it. Then we
execute the self-supervised task and the downstream task of CPC based on the representations for
each channel as MBrain does, this variant is denoted as “CPC-Conv”.

• We use the contextual representations of all n channels as input to an MLP in a fixed order, but
we set the representation of the target channel to 0 tensor when we aggregate them. By using
the output of MLP as the aggregated representation of other channels, we perform subsequent
experiments following exactly the same steps as MBrain. We name this variant as “CPC-MLP”.

We can observe that the performance of “CPC-Conv” decreases dramatically. We speculate that
this is because the channels are relatively independent, and the correlation between most channels
is weak or even non-existent. Direct adoption of multi-channel convolution may introduce spurious
and noisy correlations. However, the graph structure learning proposed by us has a sparsity assump-
tion, and the representation extraction of each channel is relatively independent, so it can effectively
learn and aggregate more significant information. For “CPC-MLP”, we use an MLP to aggregate

19

Under review as a conference paper at ICLR 2023

the representations of other channels, and then concatenate it with the representation of the target
channel to predict future data. Unlike “CPC-Con” which directly adopts multi-channel convolution
for the raw data to obtain the “mixed” low-level representations, “CPC-MLP”, like MBrain, learns
the correlation of channels based on the “separate” high-level representations. Therefore, the per-
formance of “CPC-MLP” does not drop as dramatically as that of “CPC-Conv”. It can be observed
that “CPC-MLP” outperforms “CPC” on the EEG dataset. This may result from the fact that the
number of channels in EEG dataset is only 19, while that in SEEG dataset is 52 to 124. Conse-
quently, the ablation results show that the graph structure learning we design has a reasonable and
parameter-efficient inductive assumption.

H HYPERPARAMETER ANALYSIS EXPERIMENTS

(a) Weights search for L2.

(b) Weights search for L3.

Figure 7: Sensitivity analysis on loss weights.

Sensitivity analysis on loss weights. Our loss function is defined as: L = (1−λ1−λ2)L1+λ1L2+
λ2L3, where L1, L2 and L3 are the loss of instantaneous time shift prediction task, delayed time
shift prediction task and replace discriminative task respectively, and λ1 and λ2 are hyperparameters
to balance the three pre-training tasks. We search both of the weights of λ1 and λ2 in the set {0.1,
0.2, 0.3, 0.4, 0.5} and report the tuning results with F2-score for seizure detection task on patient-A
from SEEG dataset. In 7(a) and 7(b), we can see that λ1 = 0.5 and λ2 = 0.3 lead to the optimal
performance. In addition, MBrain consistently performs better than the best baseline.

Figure 8: Sensitivity analysis on replace ratio r%.

Sensitivity analysis on replace ratio. We perform sensitivity analysis on replace ratio r% from
replace discriminative task. We search the replace ratio from 5% to 95% and report the tuning results
with F2-score for seizure detection task on patient-A from SEEG dataset. As Figure 8 shows, when
the replace ratio is set as 45%, MBrain has the best performance of 71.06±3.41. While MBrain gets

20

0.10.20.30.40.510.5500.5750.6000.6250.6500.6750.7000.7250.750F2-score2=0.3MBrainMax-base0.10.20.30.40.520.5500.5750.6000.6250.6500.6750.7000.7250.750F2-score1=0.5MBrainMax-base05152535455565758595100Replace ratio (%)0.500.550.600.650.700.750.80F2-scoreSensitivity analysis of replace ratioMBrainUnder review as a conference paper at ICLR 2023

the smallest standard deviation and the second best performance of 70.63±1.41 when the replace
ratio is set as 15%.

I FULL RESULTS

I.1 FULL RESULTS OF SEIZURE DETECTION EXPERIMENT

Table 5: The average performance of the seizure detection experiment on the SEEG dataset.

Models

SEEG

Pre.

Rec.

F1

F2

MiniRocket

22.98±0.15

66.24±0.26

31.79±0.19

43.58±0.22

CPC
SimCLR
T-Loss
TST
GTS
TS-TCC
TS2Vec

MBrain

27.65±4.49
11.06±3.95
29.29±2.65
13.60±3.48
24.29±4.26
22.10±7.65
30.56±2.17

55.07±3.52
51.54±5.87
51.55±2.53
44.65±4.21
40.39±5.80
49.94±5.41
52.83±2.89

34.20±3.40
16.60±4.68
36.00±1.97
19.80±3.73
29.16±2.97
25.32±8.02
36.03±1.72

42.73±2.57
25.41±4.95
43.13±1.57
28.41±3.29
34.17±2.36
32.74±7.95
43.35±1.59

37.97±2.75

65.07±2.68

46.45±2.25

55.28±1.77

Table 6: The average performance of the seizure detection experiment on the SEEG dataset with the
encoder of the SSL model frozen.

Models

SEEG

Pre.

Rec.

F1

F2

MiniRocket

22.98±0.15

66.24±0.26

31.79±0.19

43.58±0.22

CPC
SimCLR
T-Loss
TST
GTS
TS-TCC
TS2Vec

MBrain

26.99±4.35
10.36±2.76
29.20±3.21
13.32±3.96
23.13±3.51
23.07±7.45
30.79±3.08

54.16±4.49
50.89±6.68
50.24±3.52
45.59±4.37
42.34±4.95
50.32±7.11
51.43±3.36

32.98±3.25
15.69±3.21
35.03±1.73
19.40±3.91
28.92±2.70
26.29±6.08
35.99±2.78

41.17±2.45
24.19±3.34
41.85±1.99
28.24±2.86
34.78±2.08
34.39±5.64
42.88±2.44

37.72±5.46

63.34±4.27

44.47±4.57

53.00±4.26

Seizure detection experiment. First, we keep the initial parameters of the trained self-supervised
model unchanged, repeat the experiments five times in the fine-tuning stage of the downstream
seizure detection task, and report the mean and standard deviation results in Table 5 and 7. Next,
we freeze the entire encoder of SSL model and only train the downstream model and the classifier
in the seizure detection task. The same reproducible experimental results are shown in Table 6 and
Table 8. We can see that the performance of most models drops slightly compared with the results
without freezing the SSL model. Nevertheless, our model still has a competitive performance in
F2-score. For the supervised model MiniRocket without a learnable representation extractor, the
results remain unchanged in the two experimental settings.

21

Under review as a conference paper at ICLR 2023

Table 7: The average performance of the seizure detection experiment on the EEG dataset.

Models

Pre.

Rec.

EEG

F1

F2

AUROC

MiniRocket

22.86±0.84

63.08±1.47

33.56±1.11

46.66±1.33

75.30±0.77

CPC
SimCLR
T-Loss
TST
GTS
TS-TCC
TS2Vec

MBrain

22.81±2.04
12.63±1.62
20.72±1.26
15.65±1.54
18.86±1.09
15.55±0.88
21.40±0.63

58.31±7.55
74.88±16.77
69.25±3.99
28.59±12.93
62.51±5.04
39.76±11.08
58.31±6.14

32.50±1.24
21.33±1.95
31.82±1.08
19.65±4.36
28.88±0.88
21.89±1.20
31.24±1.18

44.02±2.43
36.78±2.61
47.00±0.50
23.87±8.09
42.54±1.48
29.60±4.64
43.24±2.78

74.53±1.00
55.86±5.36
75.88±0.49
58.20±4.27
71.69±1.88
58.63±1.62
73.35±1.02

22.13±1.03

76.99±4.49

34.32±0.90

51.34±0.97

77.96±0.97

Table 8: The average performance of the seizure detection experiment on the EEG dataset with the
encoder of the SSL model frozen.

Models

Pre.

Rec.

EEG

F1

F2

AUROC

MiniRocket

22.86±0.84

63.08±1.47

33.56±1.11

46.66±1.33

75.30±0.77

CPC
SimCLR
T-Loss
TST
GTS
TS-TCC
TS2Vec

MBrain

23.00±1.87
11.69±0.49
21.09±2.61
13.42±2.92
18.07±0.78
14.03±2.50
20.23±1.17

53.69±7.47
71.73±11.90
65.54±6.26
30.96±13.66
65.01±2.92
34.34±10.20
64.82±13.92

31.90±1.40
20.05±1.20
31.63±2.24
17.62±5.05
28.27±1.07
19.35±3.06
30.43±1.77

41.95±3.19
35.22±3.25
45.59±1.51
23.11±8.09
42.76±1.53
25.89±5.68
44.21±5.29

73.46±1.35
51.35±1.16
75.25±1.10
53.82±5.07
71.42±2.13
54.80±4.93
73.43±2.60

23.09±1.96

66.02±5.05

34.08±1.82

47.88±1.52

76.27±1.91

Significant Analysis. Due to the large variance of the experimental results, we further conduct the
significance test of the mean values to show that the performance of MBrain is indeed significantly
better than that of other baseline models. We would like to emphasize that we are primarily con-
cerned with the F2-score of the models, because in the clinical practice, doctors focus on finding as
many seizures as possible. Thus, we focus on the significant analysis of F2-score for the results of
Table 1.

We perform significance analysis according to the following procedures: (1) For SEEG data, we
first combine the repeat results of each model for each patient into one vector. For EEG data, we
directly use the vector of repeat results. Significance analysis is performed on F2 score vectors of all
models pair by pair. (2) We use Levene’s test1 to test whether two populations have homogeneity of
variance, which is a critical property in significant analysis. (3) On the condition of homogeneity of
variance, we conduct independent sample T-test2 for the two populations. We show the p-values of
Table 5 and Table 7 in Figure 9 in the form of thermal maps respectively. Considering the symmetry
of the significance test, we only show the half of the p-value matrix.

From these two figures, we can see that for EEG data, MBrain significantly outperforms other base-
lines. For SEEG data, although the performance of T-Loss and TS2Vec is not significantly different

1https://en.wikipedia.org/wiki/Levene’s_test
2https://en.wikipedia.org/wiki/Student%27s_t-test#Unpaired_and_paired_

two-sample_t-tests

22

Under review as a conference paper at ICLR 2023

(a) SEEG dataset.

(b) EEG dataset.

Figure 9: Significant analysis.

from that of MBrain at the tolerance of 0.05, the p-value was only slightly above 0.05. Therefore, in
general, MBrain is superior to other baselines models in terms of F2-score. For baselines, we can
see that MiniRocket, CPC, T-Loss, TS2Vec and GTS have similar performance on the two datasets.
And SimCLR, TST and TS-TCC perform relatively poorly.

I.2 FULL RESULTS OF DOMAIN ADAPTATION EXPERIMENT

Table 9: The performance of the domain adaptation experiment on SEEG dataset in terms of F2-
score. DA row denotes the performance of MBrain in the domain adaptation experiment setting.
Max-base and Non-DA rows represent the best performance of baselines and MBrain in the seizure
detection experiment. Bold numbers and * indicate the best and the second best performance.

Setting

Group A

Group B

B→A

C→A

D→A

A→B

C→B

D→B

DA

68.55±4.27 69.14±6.54* 68.78±4.12

41.08±2.59

46.06±3.05 46.12±2.04*

Max-base

Non-DA

Setting

62.49±2.30

70.63±1.41

Group C

39.78±2.04

46.62±2.42

Group D

A→C

B→C

D→C

A→D

B→D

C→D

DA

40.04±3.98

39.34±2.11

48.64±5.48 80.82±0.65* 79.90±1.11

80.72±1.31

Max-base

Non-DA

33.59±2.23

46.09±2.35*

75.35±0.79

83.27±0.95

In this experiment, we still keep the self-supervised model trained on the source domain unchanged
and repeat the experiments on the target domain five times in the fine-tuning stage of the down-
stream seizure detection task. The mean and standard deviation results are presented in Table 9.
It
can be observed that the variances of the results under DA setting are generally higher than those
under Non-DA setting, indicating a large variation in the patterns of patients in SEEG dataset. Nev-
ertheless, high-quality source patient data can still be used to pre-train an SSL encoder with good
average performance on the target patient. In practice, we can make predictions in an ensemble way
by training multiple classifiers.

23

MBrainMiniRocketCPCSimCLRT-LossTSTGTSTS-TCCTS2VecMBrainMiniRocketCPCSimCLRT-LossTSTGTSTS-TCCTS2Vec0.0280.0280.869<0.01<0.01<0.010.0600.9670.855<0.01<0.01<0.01<0.010.500<0.01<0.010.2210.3080.0700.2650.177<0.010.0190.0470.1050.0460.3000.5410.0540.9670.918<0.010.942<0.010.2980.0580.00.20.40.60.81.0MBrainMiniRocketCPCSimCLRT-LossTSTGTSTS-TCCTS2VecMBrainMiniRocketCPCSimCLRT-LossTSTGTSTS-TCCTS2Vec<0.01<0.010.093<0.01<0.01<0.01<0.010.6470.069<0.01<0.01<0.01<0.010.053<0.01<0.01<0.010.329<0.01<0.01<0.01<0.01<0.01<0.010.080<0.010.434<0.01<0.010.0570.6850.0160.053<0.010.669<0.010.00.20.40.60.81.0